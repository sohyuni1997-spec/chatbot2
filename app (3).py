# app (3).py
import streamlit as st
import pandas as pd
from supabase import create_client, Client
import google.generativeai as genai
from datetime import datetime, timedelta
import plotly.graph_objects as go
import re
import base64
import os

# â— legacy / hybrid ëª¨ë“ˆì€ ê·¸ëŒ€ë¡œ ì‚¬ìš© (ìˆ˜ì • ì—†ìŒ)
from legacy import fetch_db_data_legacy, query_gemini_ai_legacy
from hybrid import ask_professional_scheduler


# ==================== í™˜ê²½ ì„¤ì • ====================
st.set_page_config(page_title="orcHatStra", page_icon="ğŸ¯", layout="wide")


# ==================== ì´ë¯¸ì§€ ë¡œë”© (ì—†ì–´ë„ UI ìœ ì§€) ====================
def get_base64_of_bin_file(bin_file: str):
    candidates = [
        os.path.join("assets", bin_file),
        bin_file,
        os.path.join(os.getcwd(), bin_file),
        os.path.join(os.getcwd(), "assets", bin_file),
    ]
    if "__file__" in globals():
        candidates += [
            os.path.join(os.path.dirname(__file__), bin_file),
            os.path.join(os.path.dirname(__file__), "assets", bin_file),
        ]
    for path in candidates:
        try:
            if os.path.exists(path):
                with open(path, "rb") as f:
                    return base64.b64encode(f.read()).decode("utf-8")
        except Exception:
            pass
    return None


# âœ… ë„ˆê°€ ì“°ë˜ íŒŒì¼ëª… ìš°ì„ , ì—†ìœ¼ë©´ assets ê¸°ë³¸ëª… fallback
logo_base64 = (
    get_base64_of_bin_file("HSE.svg")
    or get_base64_of_bin_file("logo.svg")
    or get_base64_of_bin_file("logo.png")
)
ai_avatar_base64 = (
    get_base64_of_bin_file("ai ì•„ë°”íƒ€.png")
    or get_base64_of_bin_file("ai_avatar.png")
)
user_avatar_base64 = (
    get_base64_of_bin_file("ì´ë ¥ì„œ ì‚¬ì§„.vì¹´íˆ°.png")
    or get_base64_of_bin_file("user_avatar.png")
)


# ==================== CSS ====================
# âœ… í•µì‹¬: HybridëŠ” st.chat_messageë¥¼ ì“¸ ê±°ë¼ì„œ
#    [data-testid="stChatMessage"] ìˆ¨ê¹€ì€ ì ˆëŒ€ í•˜ë©´ ì•ˆ ë¨!
st.markdown(
    """
<style>
[data-testid="stHeader"] { display: none; }
.stApp { background-color: #F5F5F7; }
.main { padding-top: 90px !important; }

/* ê³ ì • í—¤ë” */
.fixed-header{
  position:fixed; top:0; left:0; right:0; height:70px;
  background:white; border-bottom:1px solid #E5E5EA;
  display:flex; align-items:center; gap:16px; padding:0 32px;
  z-index:9999;
}

/* Legacy ì¶œë ¥ ì˜ì—­ì„ êµ¬ë¶„í•˜ê³  ì‹¶ìœ¼ë©´(ì„ íƒ)
.legacy-wrap { max-width: 900px; margin: 0 auto; }
*/

/* expander */
.streamlit-expanderHeader{
  background-color: #FFFFFF !important;
  border-radius:16px !important;
  border:1px solid #E5E5EA !important;
  padding:12px 16px !important;
}
</style>
""",
    unsafe_allow_html=True,
)


# ==================== ê³ ì • í—¤ë” ====================
st.markdown(
    f"""
<div class="fixed-header">
  {f'<img src="data:image/svg+xml;base64,{logo_base64}" height="40">' if logo_base64 else ''}
  <h2 style="margin:0">orcHatStra</h2>
</div>
""",
    unsafe_allow_html=True,
)
st.markdown("<div style='height:90px'></div>", unsafe_allow_html=True)


# ==================== Secrets ì²˜ë¦¬ ====================
try:
    URL = st.secrets.get("SUPABASE_URL", "")
    KEY = st.secrets.get("SUPABASE_KEY", "")
    GENAI_KEY = st.secrets.get("GEMINI_API_KEY", "")
except Exception:
    URL, KEY, GENAI_KEY = "", "", ""

@st.cache_resource
def init_supabase():
    return create_client(URL, KEY)

supabase: Client = init_supabase()
if GENAI_KEY:
    genai.configure(api_key=GENAI_KEY)


# ==================== íŒŒë¼ë¯¸í„° ====================
CAPA_LIMITS = {"ì¡°ë¦½1": 3300, "ì¡°ë¦½2": 3700, "ì¡°ë¦½3": 3600}
TEST_MODE = True
TODAY = datetime(2026, 1, 5).date() if TEST_MODE else datetime.now().date()


# ==================== ìœ í‹¸ ====================
def extract_date(text: str | None):
    if not text:
        return None
    patterns = [
        r"(2026-\d{2}-\d{2})",
        r"(\d{1,2})/(\d{1,2})",
        r"(\d{1,2})ì›”\s*(\d{1,2})ì¼",
    ]
    for p in patterns:
        m = re.search(p, text)
        if not m:
            continue
        if p.startswith("(2026-"):
            return m.group(1)
        mm = int(m.group(1))
        dd = int(m.group(2))
        return f"2026-{mm:02d}-{dd:02d}"
    return None


@st.cache_data(ttl=600)
def fetch_data(target_date: str | None = None):
    """
    í•˜ì´ë¸Œë¦¬ë“œìš© ë°ì´í„° ë¡œë“œ
    - legacy ê²½ë¡œ ì˜í–¥ ì—†ìŒ
    """
    try:
        if target_date:
            dt = datetime.strptime(target_date, "%Y-%m-%d")
            start_date = (dt - timedelta(days=10)).strftime("%Y-%m-%d")
            end_date = (dt + timedelta(days=10)).strftime("%Y-%m-%d")
            plan_res = (
                supabase.table("production_plan_2026_01")
                .select("*")
                .gte("plan_date", start_date)
                .lte("plan_date", end_date)
                .execute()
            )
        else:
            plan_res = supabase.table("production_plan_2026_01").select("*").execute()

        plan_df = pd.DataFrame(plan_res.data) if plan_res.data else pd.DataFrame()

        hist_res = supabase.table("production_investigation").select("*").execute()
        hist_df = pd.DataFrame(hist_res.data) if hist_res.data else pd.DataFrame()

        product_map, plt_map = {}, {}
        if not plan_df.empty and "product_name" in plan_df.columns:
            plan_df["name_clean"] = plan_df["product_name"].apply(lambda x: re.sub(r"\s+", "", str(x)).strip())

            if "plt" in plan_df.columns:
                plt_map = plan_df.groupby("name_clean")["plt"].first().to_dict()

            if "line" in plan_df.columns:
                product_map = plan_df.groupby("name_clean")["line"].unique().to_dict()

            # ê¸°ì¡´ ë¡œì§ ìœ ì§€: T6ëŠ” ì „ ë¼ì¸ ê°€ëŠ¥ ì²˜ë¦¬
            for k in list(product_map.keys()):
                if "T6" in str(k).upper():
                    product_map[k] = ["ì¡°ë¦½1", "ì¡°ë¦½2", "ì¡°ë¦½3"]

        return plan_df, hist_df, product_map, plt_map

    except Exception as e:
        st.error(f"ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
        return pd.DataFrame(), pd.DataFrame(), {}, {}


def moves_to_delta_df(validated_moves: list[dict] | None) -> pd.DataFrame:
    """
    Î”(ë³€ê²½ëŸ‰) DataFrame ìƒì„±
    - í‘œ ê¹¨ì§ ë°©ì§€: expanderì—ì„œ st.dataframeìœ¼ë¡œë§Œ ë³´ì—¬ì£¼ê¸° ìœ„í•œ ë°ì´í„° ì¤€ë¹„
    """
    if not validated_moves:
        return pd.DataFrame(columns=["date", "item", "line", "delta"])

    rows = []
    for mv in validated_moves:
        item = str(mv.get("item", "")).strip()
        qty = int(mv.get("qty", 0) or 0)
        from_loc = str(mv.get("from", "") or "")
        to_loc = str(mv.get("to", "") or "")

        if not item or qty <= 0 or "_" not in from_loc or "_" not in to_loc:
            continue

        from_date, from_line = [x.strip() for x in from_loc.split("_", 1)]
        to_date, to_line = [x.strip() for x in to_loc.split("_", 1)]

        rows.append({"date": from_date, "item": item, "line": from_line, "delta": -qty})
        rows.append({"date": to_date, "item": item, "line": to_line, "delta": +qty})

    return pd.DataFrame(rows, columns=["date", "item", "line", "delta"])


# ==================== ë Œë”ë§ ====================
def render_message(msg: dict):
    """
    âœ… í•µì‹¬
    - legacy: st.markdown ê·¸ëŒ€ë¡œ (ì˜í–¥ 0)
    - hybrid: st.chat_message + st.markdown (í‘œ/ë§ˆí¬ë‹¤ìš´ ì™„ì „ ë³´ì¥)
    """
    role = msg.get("role")
    engine = msg.get("engine")  # "legacy" | "hybrid"
    content = msg.get("content", "")

    if engine == "legacy":
        # âœ… legacy 0 ì˜í–¥: ê¸°ì¡´ Streamlit markdown ë Œë”ë§ ê·¸ëŒ€ë¡œ
        st.markdown(content)
        return

    # âœ… hybridëŠ” chat_messageë¡œ ë Œë” (í‘œ/í—¤ë”/ë¦¬ìŠ¤íŠ¸ ê¹¨ì§ ë°©ì§€)
    avatar = None
    if role == "assistant" and ai_avatar_base64:
        avatar = f"data:image/png;base64,{ai_avatar_base64}"
    elif role == "user" and user_avatar_base64:
        avatar = f"data:image/png;base64,{user_avatar_base64}"

    with st.chat_message(role, avatar=avatar):
        st.markdown(content)


# ==================== ì„¸ì…˜ ìƒíƒœ ====================
if "messages" not in st.session_state:
    st.session_state.messages = []  # dict: {role, content, engine}
if "is_loading" not in st.session_state:
    st.session_state.is_loading = False
if "last_hybrid" not in st.session_state:
    st.session_state.last_hybrid = None


# ==================== ì±„íŒ… í‘œì‹œ ====================
for m in st.session_state.messages:
    if isinstance(m, dict):
        render_message(m)


# ==================== ì…ë ¥ ====================
if prompt := st.chat_input("ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”?"):
    # user ë©”ì‹œì§€ëŠ” hybridë¡œ í‘œì‹œ (ì›í•˜ë©´ legacyë¡œë„ ê°€ëŠ¥í•˜ì§€ë§Œ ì¼ë‹¨ í†µì¼)
    st.session_state.messages.append({"role": "user", "content": prompt, "engine": "hybrid"})
    st.session_state.is_loading = True
    st.rerun()


# ==================== ì‘ë‹µ ìƒì„± ====================
if st.session_state.is_loading:
    prompt = st.session_state.messages[-1]["content"]
    target_date = extract_date(prompt)

    is_adjustment_mode = bool(target_date) and (
        any(x in prompt for x in ["ì¡°ë¦½1", "ì¡°ë¦½2", "ì¡°ë¦½3", "ì¡°ë¦½"])
        or re.search(r"\d+%", prompt) is not None
        or "CAPA" in prompt.upper()
        or any(x in prompt for x in ["ì¤„ì—¬", "ëŠ˜ë ¤", "ì¶”ê°€", "ì¦ëŸ‰", "ê°ëŸ‰"])
    )

    try:
        if is_adjustment_mode:
            plan_df, hist_df, product_map, plt_map = fetch_data(target_date)

            if plan_df.empty:
                answer = "âŒ ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë‚ ì§œ/í…Œì´ë¸”ì„ í™•ì¸í•´ì£¼ì„¸ìš”."
                st.session_state.messages.append({"role": "assistant", "content": answer, "engine": "hybrid"})
                st.session_state.last_hybrid = None
            else:
                result = ask_professional_scheduler(
                    question=prompt,
                    plan_df=plan_df,
                    hist_df=hist_df,
                    product_map=product_map,
                    plt_map=plt_map,
                    question_date=target_date,
                    mode="hybrid",
                    today=TODAY,
                    capa_limits=CAPA_LIMITS,
                    genai_key=GENAI_KEY,
                )

                report, success, charts, status, validated_moves = "", False, None, "", None
                if isinstance(result, (tuple, list)):
                    if len(result) == 5:
                        report, success, charts, status, validated_moves = result
                    elif len(result) == 4:
                        report, success, charts, status = result
                    else:
                        report = str(result)
                        status = "ìƒì‚°ê³„íš ì¡°ì • ê²°ê³¼ë¥¼ íŒŒì‹±í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."
                        success = False
                else:
                    report = str(result)
                    status = "ìƒì‚°ê³„íš ì¡°ì • ê²°ê³¼ë¥¼ íŒŒì‹±í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."
                    success = False

                # âœ… Hybrid ë§í’ì„ ì—ì„œë„ í‘œê°€ â€œì•ˆ ê¹¨ì ¸ì•¼ í•œë‹¤â€ ìš”êµ¬ ë°˜ì˜:
                #    => hybrid ë‹µë³€ì€ chat_message + st.markdown ì´ë¯€ë¡œ í‘œê°€ ê¹¨ì§€ì§€ ì•ŠìŒ.
                #    (ì›í•˜ë©´ ì•„ë˜ì—ì„œ report ì „ì²´ ëŒ€ì‹  status+í•µì‹¬ë§Œ ì¶œë ¥í•˜ë„ë¡ ì¤„ì¼ ìˆ˜ë„ ìˆìŒ)
                bubble_text = f"{'âœ…' if success else 'âš ï¸'} {status}"
                st.session_state.messages.append({"role": "assistant", "content": bubble_text, "engine": "hybrid"})

                # ìƒì„¸ ë³´ê¸° ë°ì´í„° ì €ì¥ (expanderì—ì„œ í‘œ/Î”/ê²€ì¦/CAPA/ì›ë¬¸)
                st.session_state.last_hybrid = {
                    "status": status,
                    "success": bool(success),
                    "report_md": report,
                    "validated_moves": validated_moves,
                    "plan_df": plan_df,
                    "target_date": target_date,
                }

        else:
            # âœ… legacy ê²½ë¡œ (ì˜í–¥ 0)
            ctx = fetch_db_data_legacy(prompt, supabase)
            answer = ctx if ("ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤" in ctx or "ì˜¤ë¥˜" in ctx) else query_gemini_ai_legacy(prompt, ctx, GENAI_KEY)
            st.session_state.messages.append({"role": "assistant", "content": answer, "engine": "legacy"})
            st.session_state.last_hybrid = None

    except Exception as e:
        st.session_state.messages.append(
            {"role": "assistant", "content": f"âŒ **ì˜¤ë¥˜ ë°œìƒ**\n\n```\n{str(e)}\n```", "engine": "legacy"}
        )
        st.session_state.last_hybrid = None
    finally:
        st.session_state.is_loading = False
        st.rerun()


# ==================== ìƒì„¸ ë³´ê¸°(Expander + Tabs) ====================
if not st.session_state.is_loading and st.session_state.last_hybrid:
    last = st.session_state.last_hybrid
    report_md = last.get("report_md", "")
    plan_df = last.get("plan_df")
    validated_moves = last.get("validated_moves")

    st.markdown("---")
    with st.expander("ğŸ“¦ ìƒì„¸ ë³´ê¸°", expanded=False):
        t1, t2, t3, t4, t5 = st.tabs(["ğŸ§¾ ì¡°ì¹˜ê³„íš/ì›ë¬¸", "ğŸ“Š Î”(í‘œ)", "ğŸ” ê²€ì¦", "ğŸ“ˆ CAPA ê·¸ë˜í”„", "ğŸ“„ ì „ì²´ ì›ë¬¸"])

        with t1:
            # Streamlit native markdown
            st.markdown(report_md)

        with t2:
            # Î”ëŠ” dataframeìœ¼ë¡œë§Œ (í‘œ ê¹¨ì§ ì›ì²œ ì°¨ë‹¨)
            delta_df = moves_to_delta_df(validated_moves)
            if delta_df.empty:
                st.info("Î”(ë³€ê²½ëŸ‰) ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            else:
                pivot = (
                    delta_df.pivot_table(
                        index=["date", "item"],
                        columns="line",
                        values="delta",
                        aggfunc="sum",
                        fill_value=0,
                    )
                    .reset_index()
                )
                # ì»¬ëŸ¼ ì •ë ¬/ë³´ê°•
                for col in ["ì¡°ë¦½1", "ì¡°ë¦½2", "ì¡°ë¦½3"]:
                    if col not in pivot.columns:
                        pivot[col] = 0
                pivot = pivot[["date", "item", "ì¡°ë¦½1", "ì¡°ë¦½2", "ì¡°ë¦½3"]]
                st.dataframe(pivot, use_container_width=True)

        with t3:
            # ê²€ì¦/ì›ë¬¸ (ì¼ë‹¨ report ì „ì²´ë¥¼ ê·¸ëŒ€ë¡œ)
            st.markdown(report_md)

        with t4:
            # CAPA ê·¸ë˜í”„ + ìƒì„¸ ë°ì´í„°
            if isinstance(plan_df, pd.DataFrame) and (not plan_df.empty) and ("qty_1ì°¨" in plan_df.columns):
                daily = plan_df.groupby(["plan_date", "line"])["qty_1ì°¨"].sum().reset_index()
                daily.columns = ["plan_date", "line", "current_qty"]
                daily["max_capa"] = daily["line"].map(CAPA_LIMITS)
                daily["remaining_capa"] = daily["max_capa"] - daily["current_qty"]

                chart_data = daily.pivot(index="plan_date", columns="line", values="current_qty").fillna(0)

                fig = go.Figure()
                for line in ["ì¡°ë¦½1", "ì¡°ë¦½2", "ì¡°ë¦½3"]:
                    if line in chart_data.columns:
                        fig.add_trace(go.Bar(name=line, x=chart_data.index, y=chart_data[line]))

                for line, limit in CAPA_LIMITS.items():
                    fig.add_hline(
                        y=limit,
                        line_dash="dash",
                        annotation_text=f"{line} í•œê³„: {limit:,}",
                        annotation_position="right",
                    )

                fig.update_layout(
                    barmode="group",
                    height=450,
                    xaxis_title="ë‚ ì§œ",
                    yaxis_title="ìˆ˜ëŸ‰(ê°œ)",
                    legend=dict(orientation="h", yanchor="bottom", y=1.02, xanchor="right", x=1),
                    hovermode="x unified",
                    plot_bgcolor="rgba(0,0,0,0)",
                    paper_bgcolor="rgba(0,0,0,0)",
                    margin=dict(l=20, r=20, t=40, b=20),
                )

                st.plotly_chart(fig, use_container_width=True)
                st.markdown("##### ğŸ“‹ CAPA ìƒì„¸ ë°ì´í„°")
                st.dataframe(daily, use_container_width=True)
            else:
                st.info("CAPA ê·¸ë˜í”„ë¥¼ ê·¸ë¦´ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")

        with t5:
            # ì „ì²´ ì›ë¬¸ì´ ë„ˆë¬´ ê¸¸ë©´ st.textê°€ ë” ì•ˆì „í•  ë•Œë„ ìˆìŒ
            st.markdown(report_md)


# ==================== END ====================
pass
